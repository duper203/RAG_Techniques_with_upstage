{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJNpNtngoxrNu4mO/va1Q6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duper203/RAG_Techniques_with_upstage/blob/main/upstage/30_crag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corrective RAG Process: Retrieval-Augmented Generation with Dynamic Correction\n",
        "\n",
        "\n",
        "\n",
        "## Key Components\n",
        "1. FAISS Index: A vector database for efficient similarity search of pre-existing knowledge.\n",
        "2. Retrieval Evaluator: Assesses the relevance of retrieved documents to the query.\n",
        "3. Knowledge Refinement: Extracts key information from documents when necessary.\n",
        "4. Web Search Query Rewriter: Optimizes queries for web searches when local knowledge is insufficient.\n",
        "5. Response Generator: Creates human-like responses based on the accumulated knowledge."
      ],
      "metadata": {
        "id": "GJCQEVKx29LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import relevant libraries & helper functions"
      ],
      "metadata": {
        "id": "V6S1n7kf-GHk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGMx_kQQheQS"
      },
      "outputs": [],
      "source": [
        "! pip3 install -qU langchain-upstage langchain langchain-community faiss-cpu duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import List, Tuple\n",
        "import json\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")"
      ],
      "metadata": {
        "id": "LmVEhyCshlWB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter  import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the PDF file.\n",
        "        chunk_size: The desired size of each text chunk.\n",
        "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded book content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings =  UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "    return vectorstore\n",
        "def replace_t_with_space(list_of_documents):\n",
        "    \"\"\"\n",
        "    Replaces all tab characters ('\\t') with spaces in the page content of each document.\n",
        "\n",
        "    Args:\n",
        "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
        "\n",
        "    Returns:\n",
        "        The modified list of documents with tab characters replaced by spaces.\n",
        "    \"\"\"\n",
        "\n",
        "    for doc in list_of_documents:\n",
        "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
        "    return list_of_documents"
      ],
      "metadata": {
        "id": "iTd9G8zt6Jmc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define files path"
      ],
      "metadata": {
        "id": "fN5tJnYF-JrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ],
      "metadata": {
        "id": "oXwgFN015Zul"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a vector store"
      ],
      "metadata": {
        "id": "Hi9ba6ly-LRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = encode_pdf(path)"
      ],
      "metadata": {
        "id": "mkY_1cR75bEs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize language model"
      ],
      "metadata": {
        "id": "v7qTBxqP-ORp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatUpstage()"
      ],
      "metadata": {
        "id": "ol-i4yLe5ezu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize search tool"
      ],
      "metadata": {
        "id": "NTVLVViM-QxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search = DuckDuckGoSearchResults()"
      ],
      "metadata": {
        "id": "sJLEElID5d97"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define retrieval evaluator, knowledge refinement and query rewriter llm chains"
      ],
      "metadata": {
        "id": "OFl4pc10-Srp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval Evaluator\n",
        "class RetrievalEvaluatorInput(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. the score should be between 0 and 1.\")\n",
        "def retrieval_evaluator(query: str, document: str) -> float:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"document\"],\n",
        "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
        "    )\n",
        "    chain = prompt | llm.with_structured_output(RetrievalEvaluatorInput)\n",
        "    input_variables = {\"query\": query, \"document\": document}\n",
        "    result = chain.invoke(input_variables).relevance_score\n",
        "    return result\n",
        "\n",
        "# Knowledge Refinement\n",
        "class KnowledgeRefinementInput(BaseModel):\n",
        "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
        "def knowledge_refinement(document: str) -> List[str]:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"document\"],\n",
        "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
        "    )\n",
        "    chain = prompt | llm.with_structured_output(KnowledgeRefinementInput)\n",
        "    input_variables = {\"document\": document}\n",
        "    result = chain.invoke(input_variables).key_points\n",
        "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
        "\n",
        "# Web Search Query Rewriter\n",
        "class QueryRewriterInput(BaseModel):\n",
        "    query: str = Field(..., description=\"The query to rewrite.\")\n",
        "def rewrite_query(query: str) -> str:\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
        "    )\n",
        "    chain = prompt | llm.with_structured_output(QueryRewriterInput)\n",
        "    input_variables = {\"query\": query}\n",
        "    return chain.invoke(input_variables).query.strip()"
      ],
      "metadata": {
        "id": "C_MvFdcS5g1a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper function to parse search results"
      ],
      "metadata": {
        "id": "Pk90I8gS-VYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Parse a JSON string of search results into a list of title-link tuples.\n",
        "\n",
        "    Args:\n",
        "        results_string (str): A JSON-formatted string containing search results.\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[str, str]]: A list of tuples, where each tuple contains the title and link of a search result.\n",
        "                               If parsing fails, an empty list is returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to parse the JSON string\n",
        "        results = json.loads(results_string)\n",
        "        # Extract and return the title and link from each result\n",
        "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle JSON decoding errors by returning an empty list\n",
        "        print(\"Error parsing search results. Returning empty list.\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "05ueJsuw5iJp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define sub functions for the CRAG process"
      ],
      "metadata": {
        "id": "OffDo_Ux-W9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieve documents based on a query using a FAISS index.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "        faiss_index (FAISS): The FAISS index used for similarity search.\n",
        "        k (int): The number of top documents to retrieve. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of the retrieved document contents.\n",
        "    \"\"\"\n",
        "    docs = faiss_index.similarity_search(query, k=k)\n",
        "    return [doc.page_content for doc in docs]\n",
        "\n",
        "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Evaluate the relevance of documents based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        documents (List[str]): A list of document contents to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of relevance scores for each document.\n",
        "    \"\"\"\n",
        "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
        "\n",
        "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
        "    \"\"\"\n",
        "    Perform a web search based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to search for.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[Tuple[str, str]]]:\n",
        "            - A list of refined knowledge obtained from the web search.\n",
        "            - A list of tuples containing titles and links of the sources.\n",
        "    \"\"\"\n",
        "    rewritten_query = rewrite_query(query)\n",
        "    web_results = search.run(rewritten_query)\n",
        "    web_knowledge = knowledge_refinement(web_results)\n",
        "    sources = parse_search_results(web_results)\n",
        "    return web_knowledge, sources\n",
        "\n",
        "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
        "    \"\"\"\n",
        "    Generate a response to a query using knowledge and sources.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string.\n",
        "        knowledge (str): The refined knowledge to use in the response.\n",
        "        sources (List[Tuple[str, str]]): A list of tuples containing titles and links of the sources.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
        "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
        "    )\n",
        "    input_variables = {\n",
        "        \"query\": query,\n",
        "        \"knowledge\": knowledge,\n",
        "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
        "    }\n",
        "    response_chain = response_prompt | llm\n",
        "    return response_chain.invoke(input_variables).content"
      ],
      "metadata": {
        "id": "HeNwqdat5kCv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CRAG process"
      ],
      "metadata": {
        "id": "_6NP90xc-ZQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
        "    \"\"\"\n",
        "    Process a query by retrieving, evaluating, and using documents or performing a web search to generate a response.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string to process.\n",
        "        faiss_index (FAISS): The FAISS index used for document retrieval.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response based on the query.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing query: {query}\")\n",
        "\n",
        "    # Retrieve and evaluate documents\n",
        "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
        "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
        "\n",
        "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
        "    print(f\"Evaluation scores: {eval_scores}\")\n",
        "\n",
        "    # Determine action based on evaluation scores\n",
        "    max_score = max(eval_scores)\n",
        "    sources = []\n",
        "\n",
        "    if max_score > 0.7:\n",
        "        print(\"\\nAction: Correct - Using retrieved document\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        final_knowledge = best_doc\n",
        "        sources.append((\"Retrieved document\", \"\"))\n",
        "    elif max_score < 0.3:\n",
        "        print(\"\\nAction: Incorrect - Performing web search\")\n",
        "        final_knowledge, sources = perform_web_search(query)\n",
        "    else:\n",
        "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
        "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
        "        # Refine the retrieved knowledge\n",
        "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
        "        web_knowledge, web_sources = perform_web_search(query)\n",
        "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
        "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
        "\n",
        "    print(\"\\nFinal knowledge:\")\n",
        "    print(final_knowledge)\n",
        "\n",
        "    print(\"\\nSources:\")\n",
        "    for title, link in sources:\n",
        "        print(f\"{title}: {link}\" if link else title)\n",
        "\n",
        "    # Generate response\n",
        "    print(\"\\nGenerating response...\")\n",
        "    response = generate_response(query, final_knowledge, sources)\n",
        "\n",
        "    print(\"\\nResponse generated\")\n",
        "    return response"
      ],
      "metadata": {
        "id": "PRKEiYRJ5mEp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example query with high relevance to the document"
      ],
      "metadata": {
        "id": "zLaXeITE-cgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the main causes of climate change?\"\n",
        "result = crag_process(query, vectorstore)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Answer: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZNQRGVt5moy",
        "outputId": "5a669679-38ae-456b-a2cf-e977ea78eb18"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing query: What are the main causes of climate change?\n",
            "\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [0.9, 0.8, 0.8]\n",
            "\n",
            "Action: Correct - Using retrieved document\n",
            "\n",
            "Final knowledge:\n",
            "driven by human activities, particularly the emission of greenhou se gases.  \n",
            "Chapter 2: Causes of Climate Change  \n",
            "Greenhouse Gases  \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
            "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is  essential \n",
            "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
            "activities have intensified this natural process, leading to a warmer climate.  \n",
            "Fossil Fuels  \n",
            "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
            "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
            "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
            "today.  \n",
            "Coal\n",
            "\n",
            "Sources:\n",
            "Retrieved document\n",
            "\n",
            "Generating response...\n",
            "\n",
            "Response generated\n",
            "Query: What are the main causes of climate change?\n",
            "Answer: The main causes of climate change are driven by human activities, particularly the emission of greenhouse gases. The primary cause of recent climate change is the increase in greenhouse gases in the atmosphere, such as carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O), which trap heat from the sun and create a \"greenhouse effect.\" This effect is essential for life on Earth, as it keeps the planet warm enough to support life. However, human activities have intensified this natural process, leading to a warmer climate. Burning fossil fuels for energy, including coal, oil, and natural gas used for electricity, heating, and transportation, releases large amounts of CO2 and has contributed significantly to the increase in greenhouse gases in the atmosphere. The industrial revolution marked the beginning of a significant increase in fossil fuel consumption, which continues to rise today.\n",
            "\n",
            "Sources:\n",
            "- Retrieved document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example query with low relevance to the document"
      ],
      "metadata": {
        "id": "7iwIg3GN-dmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how did harry beat quirrell?\"\n",
        "result = crag_process(query, vectorstore)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Answer: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Su7bmfv5oH2",
        "outputId": "23c6422f-5992-4891-94fa-36039538efdd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing query: how did harry beat quirrell?\n",
            "\n",
            "Retrieved 3 documents\n",
            "Evaluation scores: [0.0, 0.01, 0.0]\n",
            "\n",
            "Action: Incorrect - Performing web search\n",
            "Error parsing search results. Returning empty list.\n",
            "\n",
            "Final knowledge:\n",
            "[\"snippet: As Harry looks into the Mirror of Erised, he sees himself holding the Philosophers' stone. Voldemort orders Quirrell to kill Harry but as Quirrell is choking him, Harry puts his hands on Quirrell's face, burning him to ashes. Voldemort's soul rises and tries to kill harry but in vain and leaves.\", \"title: Harry Potter & The Philosopher's Stone (2011) Ending Explained - Who's ...\", 'link: https://www.thereviewgeek.com/harrypotter-endingexplained/', \"snippet: Harry survived the second Killing Curse because a piece of Voldemort's soul lived inside him, and when Voldemort cast the curse, it only killed the piece of his soul inside Harry. Harry's connection with Voldemort helped him time and time again, including surviving the killing curse for the second time. It's important to remember the ongoing ...\", \"title: How Did Harry Potter Survive Voldemort's Second Avada Kedavra? - CBR\", 'link: https://www.cbr.com/why-harry-potter-did-not-die-deathly-hallows/', \"snippet: Why Harry's Hands Burned Quirrell. Harry Potter fans around the world were left in suspense during the iconic scene in Harry Potter and the Sorcerer's Stone when Harry's touch caused Quirrell's hands to burn. It's a moment that had us all on the edge of our seats, wondering what could possibly explain such a bizarre phenomenon.\", \"title: The Burning Mystery of Harry's Hands: Unraveling the Enigma of Quirrell ...\", 'link: https://gcelt.org/the-burning-mystery-of-harrys-hands-unraveling-the-enigma-of-quirrells-peril/', \"snippet: Horcrux is gone at easter break instead of the battle of Hogwarts. Harry doesn't have to walk out into the woods anymore. If he does walk out to the woods and tries to die he doesn't come back this time. This could see Voldemort using Legilimency on Peter to see what happened and now be even more spooked of Harry and his abilities to survive.\", \"title: Book one - Why does Quirrell curse Harry's broom : r/harrypotter - Reddit\", 'link: https://www.reddit.com/r/harrypotter/comments/18fjfjh/book_one_why_does_quirrell_curse_harrys_broom/']\n",
            "\n",
            "Sources:\n",
            "\n",
            "Generating response...\n",
            "\n",
            "Response generated\n",
            "Query: how did harry beat quirrell?\n",
            "Answer: Harry beat Quirrell by using his connection with Voldemort's soul. In the climax of \"Harry Potter and the Philosopher's Stone,\" Voldemort, who is possessing Professor Quirrell, orders Quirrell to kill Harry. As Quirrell is choking Harry, Harry puts his hands on Quirrell's face, burning him to ashes. This is because Voldemort's soul, which is residing in Quirrell's turban, is weakened by Harry's touch. Voldemort's soul rises and tries to kill Harry, but Harry is protected by the magical stone, which he had touched earlier in the Mirror of Erised.\n",
            "\n",
            "Sources:\n",
            "\n",
            "1. \"Harry Potter & The Philosopher's Stone (2011) Ending Explained - Who's ...\", <https://www.thereviewgeek.com/harrypotter-endingexplained/>\n",
            "2. \"How Did Harry Potter Survive Voldemort's Second Avada Kedavra? - CBR\", <https://www.cbr.com/why-harry-potter-did-not-die-deathly-hallows/>\n",
            "3. \"The Burning Mystery of Harry's Hands: Unraveling the Enigma of Quirrell ...\", <https://gcelt.org/the-burning-mystery-of-harrys-hands-unraveling-the-enigma-of-quirrells-peril/>\n"
          ]
        }
      ]
    }
  ]
}