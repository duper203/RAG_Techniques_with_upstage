{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1LmQNRBtSI/SpsBqs2LXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duper203/RAG_Techniques_with_upstage/blob/main/upstage/20_retrieval_with_feedback_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG System with Feedback Loop: Enhancing Retrieval and Response Quality\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. PDF Content Extraction: Extracts text from PDF documents\n",
        "2. Vectorstore: Stores and indexes document embeddings for efficient retrieval\n",
        "3. Retriever: Fetches relevant documents based on user queries\n",
        "4. Language Model: Generates responses using retrieved documents\n",
        "5. Feedback Collection: Gathers user feedback on response quality and relevance\n",
        "6. Feedback Storage: Persists user feedback for future use\n",
        "7. Relevance Score Adjustment: Modifies document relevance based on feedback\n",
        "8. Index Fine-tuning: Periodically updates the vectorstore using accumulated feedback\n",
        "\n",
        "\n",
        "\n",
        "## Method Details\n",
        "\n",
        "1. Initial Setup\n",
        "2. Query Processing\n",
        "3. Feedback Collection\n",
        "4. Relevance Score Adjustment\n",
        "5. Retriever Update\n",
        "6. Periodic Index Fine-tuning"
      ],
      "metadata": {
        "id": "_4vTJ_fSflby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install -qU langchain-upstage langchain langchain-community faiss-cpu PyMuPDF"
      ],
      "metadata": {
        "id": "MFxiQBMlWmjl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_upstage import ChatUpstage, UpstageEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ],
      "metadata": {
        "id": "z_2vs2-ob4R3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define document(s) path & Read PDf to string"
      ],
      "metadata": {
        "id": "DhaAjrWHY20s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ],
      "metadata": {
        "id": "fSlBtO2-UuAq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pdf_to_string(path):\n",
        "    \"\"\"\n",
        "    Read a PDF document from the specified path and return its content as a string.\n",
        "\n",
        "    Args:\n",
        "        path (str): The file path to the PDF document.\n",
        "\n",
        "    Returns:\n",
        "        str: The concatenated text content of all pages in the PDF document.\n",
        "\n",
        "    The function uses the 'fitz' library (PyMuPDF) to open the PDF document, iterate over each page,\n",
        "    extract the text content from each page, and append it to a single string.\n",
        "    \"\"\"\n",
        "    # Open the PDF document located at the specified path\n",
        "    doc = fitz.open(path)\n",
        "    content = \"\"\n",
        "    # Iterate over each page in the document\n",
        "    for page_num in range(len(doc)):\n",
        "        # Get the current page\n",
        "        page = doc[page_num]\n",
        "        # Extract the text content from the current page and append it to the content string\n",
        "        content += page.get_text()\n",
        "    return content"
      ],
      "metadata": {
        "id": "9zpEa8A615i6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "def encode_from_string(content, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a string into a vector store using OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        content (str): The text content to be encoded.\n",
        "        chunk_size (int): The size of each chunk of text.\n",
        "        chunk_overlap (int): The overlap between chunks.\n",
        "\n",
        "    Returns:\n",
        "        FAISS: A vector store containing the encoded content.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the input content is not valid.\n",
        "        RuntimeError: If there is an error during the encoding process.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(content, str) or not content.strip():\n",
        "        raise ValueError(\"Content must be a non-empty string.\")\n",
        "\n",
        "    if not isinstance(chunk_size, int) or chunk_size <= 0:\n",
        "        raise ValueError(\"chunk_size must be a positive integer.\")\n",
        "\n",
        "    if not isinstance(chunk_overlap, int) or chunk_overlap < 0:\n",
        "        raise ValueError(\"chunk_overlap must be a non-negative integer.\")\n",
        "\n",
        "    try:\n",
        "        # Split the content into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            length_function=len,\n",
        "            is_separator_regex=False,\n",
        "        )\n",
        "        chunks = text_splitter.create_documents([content])\n",
        "\n",
        "        # Assign metadata to each chunk\n",
        "        for chunk in chunks:\n",
        "            chunk.metadata['relevance_score'] = 1.0\n",
        "\n",
        "        # Generate embeddings and create the vector store\n",
        "        embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
        "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"An error occurred during the encoding process: {str(e)}\")\n",
        "\n",
        "    return vectorstore\n"
      ],
      "metadata": {
        "id": "1iFmFNLe2Jka"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = read_pdf_to_string(path)\n",
        "vectorstore = encode_from_string(content)\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "X0dgwNPOwg80"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatUpstage(model=\"solar-pro\")\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)"
      ],
      "metadata": {
        "id": "82JX6l-O4qlN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_feedback(query, response, relevance, quality, comments=\"\"):\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"response\": response,\n",
        "        \"relevance\": int(relevance),\n",
        "        \"quality\": int(quality),\n",
        "        \"comments\": comments\n",
        "    }"
      ],
      "metadata": {
        "id": "nh8pA4Z52_LR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_feedback(feedback):\n",
        "    with open(\"data/feedback_data.json\", \"a\") as f:\n",
        "        json.dump(feedback, f)\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "FvDJt4eO3AMj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_feedback_data():\n",
        "    feedback_data = []\n",
        "    try:\n",
        "        with open(\"data/feedback_data.json\", \"r\") as f:\n",
        "            for line in f:\n",
        "                feedback_data.append(json.loads(line.strip()))\n",
        "    except FileNotFoundError:\n",
        "        print(\"No feedback data file found. Starting with empty feedback.\")\n",
        "    return feedback_data"
      ],
      "metadata": {
        "id": "y0ysEPHL3CL6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "class Response(BaseModel):\n",
        "    answer: str = Field(..., title=\"The answer to the question. The options can be only 'Yes' or 'No'\")\n",
        "\n",
        "def adjust_relevance_scores(query: str, docs: List[Any], feedback_data: List[Dict[str, Any]]) -> List[Any]:\n",
        "    # Create a prompt template for relevance checking\n",
        "    relevance_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\", \"feedback_query\", \"doc_content\", \"feedback_response\"],\n",
        "        template=\"\"\"\n",
        "        Determine if the following feedback response is relevant to the current query and document content.\n",
        "        You are also provided with the Feedback original query that was used to generate the feedback response.\n",
        "        Current query: {query}\n",
        "        Feedback query: {feedback_query}\n",
        "        Document content: {doc_content}\n",
        "        Feedback response: {feedback_response}\n",
        "\n",
        "        Is this feedback relevant? Respond with only 'Yes' or 'No'.\n",
        "        \"\"\"\n",
        "    )\n",
        "    llm = ChatUpstage()\n",
        "\n",
        "    # Create an LLMChain for relevance checking\n",
        "    relevance_chain = relevance_prompt | llm.with_structured_output(Response)\n",
        "\n",
        "    for doc in docs:\n",
        "        relevant_feedback = []\n",
        "\n",
        "        for feedback in feedback_data:\n",
        "            # Use LLM to check relevance\n",
        "            input_data = {\n",
        "                \"query\": query,\n",
        "                \"feedback_query\": feedback['query'],\n",
        "                \"doc_content\": doc.page_content[:1000],\n",
        "                \"feedback_response\": feedback['response']\n",
        "            }\n",
        "            # result = relevance_chain.invoke(input_data).answer\n",
        "\n",
        "            # if result == 'yes':\n",
        "            #     relevant_feedback.append(feedback)\n",
        "            result = relevance_chain.invoke(input_data)\n",
        "\n",
        "            if result is not None and result.answer.lower() == 'yes':  # Check if the result is valid\n",
        "                relevant_feedback.append(feedback)\n",
        "\n",
        "\n",
        "        # Adjust the relevance score based on feedback\n",
        "        if relevant_feedback:\n",
        "            avg_relevance = sum(f['relevance'] for f in relevant_feedback) / len(relevant_feedback)\n",
        "            doc.metadata['relevance_score'] *= (avg_relevance / 3)  # Assuming a 1-5 scale, 3 is neutral\n",
        "\n",
        "    # Re-rank documents based on adjusted scores\n",
        "    return sorted(docs, key=lambda x: x.metadata['relevance_score'], reverse=True)"
      ],
      "metadata": {
        "id": "j_fCgIxd3JC-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_index(feedback_data: List[Dict[str, Any]], texts: List[str]) -> Any:\n",
        "    # Filter high-quality responses\n",
        "    good_responses = [f for f in feedback_data if f['relevance'] >= 4 and f['quality'] >= 4]\n",
        "\n",
        "    # Extract queries and responses, and create new documents\n",
        "    additional_texts = []\n",
        "    for f in good_responses:\n",
        "        combined_text = f['query'] + \" \" + f['response']\n",
        "        additional_texts.append(combined_text)\n",
        "\n",
        "    # make the list a string\n",
        "    additional_texts = \" \".join(additional_texts)\n",
        "\n",
        "    # Create a new index with original and high-quality texts\n",
        "    all_texts = texts + additional_texts\n",
        "    new_vectorstore = encode_from_string(all_texts)\n",
        "\n",
        "    return new_vectorstore\n"
      ],
      "metadata": {
        "id": "EM-5RS4F3NGg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the greenhouse effect?\"\n",
        "\n",
        "# Get response from RAG system\n",
        "response = qa_chain(query)"
      ],
      "metadata": {
        "id": "4l2Q2-Lf4TAo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "HFN41r3pnX-m",
        "outputId": "892ddba4-8de6-4e63-aba8-7fd0b04462f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The greenhouse effect is a natural process that occurs when certain gases in the Earth\\'s atmosphere, such as carbon dioxide, methane, and nitrous oxide, trap heat from the sun, creating a \"greenhouse\" effect. This effect is essential for life on Earth, as it keeps the planet warm enough to support life. However, human activities have intensified this natural process, leading to a warmer climate.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the greenhouse effect?\"\n",
        "\n",
        "# Get response from RAG system\n",
        "response = qa_chain(query)[\"result\"]\n",
        "\n",
        "relevance = 5\n",
        "quality = 5\n",
        "\n",
        "# Collect feedback\n",
        "feedback = get_user_feedback(query, response, relevance, quality)\n",
        "\n",
        "# Store feedback\n",
        "store_feedback(feedback)\n",
        "\n",
        "# Adjust relevance scores for future retrievals\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "adjusted_docs = adjust_relevance_scores(query, docs, load_feedback_data())\n",
        "\n",
        "# Update the retriever with adjusted docs\n",
        "retriever.search_kwargs['k'] = len(adjusted_docs)\n",
        "retriever.search_kwargs['docs'] = adjusted_docs"
      ],
      "metadata": {
        "id": "WG41aM4b3OBA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Periodically (e.g., daily or weekly), fine-tune the index\n",
        "new_vectorstore = fine_tune_index(load_feedback_data(), content)\n",
        "retriever = new_vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "SJIB3pip3PXo"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}