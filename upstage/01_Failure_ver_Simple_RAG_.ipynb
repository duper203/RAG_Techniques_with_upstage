{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duper203/RAG_Techniques_with_upstage/blob/main/upstage/01_Failure_ver_Simple_RAG_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple RAG (Retrieval-Augmented Generation) System\n"
      ],
      "metadata": {
        "id": "emWlJR1aOIWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Components\n",
        "1. PDF processing and text extraction\n",
        "2. Text chunking for manageable processing\n",
        "3. Vector store creation using FAISS and Upstage embeddings\n",
        "4. Retriever setup for querying the processed documents\n",
        "5. Evaluation of the RAG system"
      ],
      "metadata": {
        "id": "8mnUs-G0OPoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method Details\n",
        "\n",
        "### Document Preprocessing\n",
        "\n",
        "\n",
        "\n",
        "*  The PDF is loaded using PyPDFLoader\n",
        "*  The text is split into chunks using RecursiveCharacterTextSplitter with specified chunk size and overlap.\n",
        "\n",
        "\n",
        "### Text Cleaning\n",
        "A custom function `replace_t_with_space` is applied to clean the text chunks. This likely addresses specific formatting issues in the PDF.\n",
        "\n",
        "### Vector Store Creation\n",
        "* Upstage embeddings are used to create vector representations of the text chunks.\n",
        "* A FAISS vector store is created from these embeddings for efficient similarity search.\n",
        "\n",
        "### Retriever Setup\n",
        "A retriever is configured to fetch the top 2 most relevant chunks for a given query."
      ],
      "metadata": {
        "id": "hZLEJ-7NOrJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Functions and Environment Settings"
      ],
      "metadata": {
        "id": "Ljr6iQE0Pk7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions\n",
        "* `replace_t_with_space` : Replaces all tab characters ('\\t') with spaces\n",
        "* `retrieve_context_per_question` : Retrieves relevant context and unique URLs for a given question\n",
        "* `show_context` : Display the contents of the provided context list"
      ],
      "metadata": {
        "id": "tqH2RjuRPxOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_t_with_space(list_of_documents):\n",
        "    \"\"\"\n",
        "    Replaces all tab characters ('\\t') with spaces in the page content of each document.\n",
        "\n",
        "    Args:\n",
        "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
        "\n",
        "    Returns:\n",
        "        The modified list of documents with tab characters replaced by spaces.\n",
        "    \"\"\"\n",
        "\n",
        "    for doc in list_of_documents:\n",
        "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
        "    return list_of_documents"
      ],
      "metadata": {
        "id": "aGCy2f_5PrWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context_per_question(question, chunks_query_retriever):\n",
        "    \"\"\"\n",
        "    Retrieves relevant context and unique URLs for a given question using the chunks query retriever.\n",
        "\n",
        "    Args:\n",
        "        question: The question for which to retrieve context and URLs.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - A string with the concatenated content of relevant documents.\n",
        "        - A list of unique URLs from the metadata of the relevant documents.\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve relevant documents for the given question\n",
        "    docs = chunks_query_retriever.get_relevant_documents(question)\n",
        "\n",
        "    # Concatenate document content\n",
        "    context = [doc.page_content for doc in docs]\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "MxRdvRU-P8ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_context(context):\n",
        "    \"\"\"\n",
        "    Display the contents of the provided context list.\n",
        "\n",
        "    Args:\n",
        "        context (list): A list of context items to be displayed.\n",
        "\n",
        "    Prints each context item in the list with a heading indicating its position.\n",
        "    \"\"\"\n",
        "    for i, c in enumerate(context):\n",
        "        print(f\"Context {i + 1}:\")\n",
        "        print(c)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "AFLsGw2lQG5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries and environment variables\n"
      ],
      "metadata": {
        "id": "rbxwK8wEPUB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install -qU langchain-upstage langchain-community pypdf faiss-cpu deepeval"
      ],
      "metadata": {
        "id": "guaAiLcXGDb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZp3g-glF4LP"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"UPSTAGE_API_KEY\"] = userdata.get(\"UPSTAGE_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Preprocessing"
      ],
      "metadata": {
        "id": "g-ApMoR4Pbv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"Understanding_Climate_Change.pdf\""
      ],
      "metadata": {
        "id": "3TqCpVx1GJ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_upstage import UpstageEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a PDF book into a vector store using Upstage embeddings.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the PDF file.\n",
        "        chunk_size: The desired size of each text chunk.\n",
        "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded book content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "d-FEHeUvQqHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)"
      ],
      "metadata": {
        "id": "rMJb0yzbHGdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Retriever"
      ],
      "metadata": {
        "id": "TP-aKjGDRPmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})\n"
      ],
      "metadata": {
        "id": "rd8lfJJ1JfJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Retriever"
      ],
      "metadata": {
        "id": "L3zhs7oZRWWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_query = \"What is the main cause of climate change?\"\n",
        "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
        "show_context(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkCksmnRJbFJ",
        "outputId": "e8e8a15e-1c06-4134-daf7-dd0bfede93c7"
      },
      "execution_count": null,
      "outputs": [
        
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context 1:\n",
            "driven by human activities, particularly the emission of greenhou se gases.  \n",
            "Chapter 2: Causes of Climate Change  \n",
            "Greenhouse Gases  \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
            "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is  essential \n",
            "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
            "activities have intensified this natural process, leading to a warmer climate.  \n",
            "Fossil Fuels  \n",
            "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
            "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
            "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
            "today.  \n",
            "Coal\n",
            "\n",
            "\n",
            "Context 2:\n",
            "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
            "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
            "began at the end of the last ice age, human societies f lourished, but the industrial era has seen \n",
            "unprecedented changes.  \n",
            "Modern Observations  \n",
            "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
            "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
            "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
            "provide a historical record that scientists use to understand past climate conditions and \n",
            "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
            "driven by human activities, particularly the emission of greenhou se gases.  \n",
            "Chapter 2: Causes of Climate Change  \n",
            "Greenhouse Gases\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "V7y51_xobdod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from deepeval.test_case import LLMTestCase\n",
        "def create_deep_eval_test_cases(\n",
        "    questions: List[str],\n",
        "    gt_answers: List[str],\n",
        "    generated_answers: List[str],\n",
        "    retrieved_documents: List[str]\n",
        ") -> List[LLMTestCase]:\n",
        "    \"\"\"\n",
        "    Create a list of LLMTestCase objects for evaluation.\n",
        "\n",
        "    Args:\n",
        "        questions (List[str]): List of input questions.\n",
        "        gt_answers (List[str]): List of ground truth answers.\n",
        "        generated_answers (List[str]): List of generated answers.\n",
        "        retrieved_documents (List[str]): List of retrieved documents.\n",
        "\n",
        "    Returns:\n",
        "        List[LLMTestCase]: List of LLMTestCase objects.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        LLMTestCase(\n",
        "            input=question,\n",
        "            expected_output=gt_answer,\n",
        "            actual_output=generated_answer,\n",
        "            retrieval_context=retrieved_document\n",
        "        )\n",
        "        for question, gt_answer, generated_answer, retrieved_document in zip(\n",
        "            questions, gt_answers, generated_answers, retrieved_documents\n",
        "        )\n",
        "    ]"
      ],
      "metadata": {
        "id": "PZ7yPapWaObA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_upstage import ChatUpstage\n",
        "import json\n",
        "\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import GEval, FaithfulnessMetric, ContextualRelevancyMetric\n",
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
        "\n",
        "# Define evaluation metrics\n",
        "correctness_metric = GEval(\n",
        "    name=\"Correctness\",\n",
        "    model=\"gpt-4o\",\n",
        "    evaluation_params=[\n",
        "        LLMTestCaseParams.EXPECTED_OUTPUT,\n",
        "        LLMTestCaseParams.ACTUAL_OUTPUT\n",
        "    ],\n",
        "    evaluation_steps=[\n",
        "        \"Determine whether the actual output is factually correct based on the expected output.\"\n",
        "    ],\n",
        ")\n",
        "\n",
        "faithfulness_metric = FaithfulnessMetric(\n",
        "    threshold=0.7,\n",
        "    model=\"gpt-4\",\n",
        "    include_reason=False\n",
        ")\n",
        "\n",
        "relevance_metric = ContextualRelevancyMetric(\n",
        "    threshold=1,\n",
        "    model=\"gpt-4\",\n",
        "    include_reason=True\n",
        ")\n",
        "\n",
        "def evaluate_rag(chunks_query_retriever, num_questions: int = 5) -> None:\n",
        "    \"\"\"\n",
        "    Evaluate the RAG system using predefined metrics.\n",
        "\n",
        "    Args:\n",
        "        chunks_query_retriever: Function to retrieve context chunks for a given query.\n",
        "        num_questions (int): Number of questions to evaluate (default: 5).\n",
        "    \"\"\"\n",
        "    llm = ChatUpstage()\n",
        "    question_answer_from_context_chain = create_question_answer_from_context_chain(llm)\n",
        "\n",
        "    # Load questions and answers from JSON file\n",
        "    q_a_file_name = \"q_a.json\"\n",
        "    with open(q_a_file_name, \"r\", encoding=\"utf-8\") as json_file:\n",
        "        q_a = json.load(json_file)\n",
        "\n",
        "    questions = [qa[\"question\"] for qa in q_a][:num_questions]\n",
        "    ground_truth_answers = [qa[\"answer\"] for qa in q_a][:num_questions]\n",
        "    generated_answers = []\n",
        "    retrieved_documents = []\n",
        "\n",
        "    # Generate answers and retrieve documents for each question\n",
        "    for question in questions:\n",
        "        context = retrieve_context_per_question(question, chunks_query_retriever)\n",
        "        retrieved_documents.append(context)\n",
        "        context_string = \" \".join(context)\n",
        "        result = answer_question_from_context(question, context_string, question_answer_from_context_chain)\n",
        "        print(\"result : \"+ str(result))\n",
        "        generated_answers.append(result[\"answer\"])\n",
        "\n",
        "    # Create test cases and evaluate\n",
        "    test_cases = create_deep_eval_test_cases(questions, ground_truth_answers, generated_answers, retrieved_documents)\n",
        "    evaluate(\n",
        "        test_cases=test_cases,\n",
        "        metrics=[correctness_metric, faithfulness_metric, relevance_metric]\n",
        "    )"
      ],
      "metadata": {
        "id": "wcuy1naoK-xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "def create_question_answer_from_context_chain(llm):\n",
        "    # Initialize the ChatOpenAI model with specific parameters\n",
        "    question_answer_from_context_llm = llm\n",
        "\n",
        "    # Define the prompt template for chain-of-thought reasoning\n",
        "    question_answer_prompt_template = \"\"\"\n",
        "    For the question below, provide a concise but suffice answer based ONLY on the provided context:\n",
        "    {context}\n",
        "    Question\n",
        "    {question}\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a PromptTemplate object with the specified template and input variables\n",
        "    question_answer_from_context_prompt = PromptTemplate(\n",
        "        template=question_answer_prompt_template,\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    # Create a chain by combining the prompt template and the language model\n",
        "    question_answer_from_context_cot_chain = question_answer_from_context_prompt | question_answer_from_context_llm.with_structured_output(\n",
        "        QuestionAnswerFromContext)\n",
        "    return question_answer_from_context_cot_chain"
      ],
      "metadata": {
        "id": "e7i6aUTeMeaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "class QuestionAnswerFromContext(BaseModel):\n",
        "    \"\"\"\n",
        "    Model to generate an answer to a query based on a given context.\n",
        "\n",
        "    Attributes:\n",
        "        answer_based_on_content (str): The generated answer based on the context.\n",
        "    \"\"\"\n",
        "    answer_based_on_content: str = Field(description=\"Generates an answer to a query based on a given context.\")\n"
      ],
      "metadata": {
        "id": "l5bgobSFNHis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_from_context(question, context, question_answer_from_context_chain):\n",
        "    \"\"\"\n",
        "    Answer a question using the given context by invoking a chain of reasoning.\n",
        "\n",
        "    Args:\n",
        "        question: The question to be answered.\n",
        "        context: The context to be used for answering the question.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the answer, context, and question.\n",
        "    \"\"\"\n",
        "    input_data = {\n",
        "        \"question\": question,\n",
        "        \"context\": context\n",
        "    }\n",
        "    print(\"Answering the question from the retrieved context...\")\n",
        "\n",
        "\n",
        "\n",
        "    output = question_answer_from_context_chain.invoke(input_data)\n",
        "    print(\"output : \"+ str(output))\n",
        "\n",
        "    if output is not None:\n",
        "        answer = output.answer_based_on_content\n",
        "        return {\"answer\": answer, \"context\": context, \"question\": question}\n"
      ],
      "metadata": {
        "id": "Cehvco3hNj5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_rag(chunks_query_retriever)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "5-7C3GdFKuU0",
        "outputId": "e6f74ed6-6aee-4474-81e3-20fa431325ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answering the question from the retrieved context...\n",
            "output : answer_based_on_content='What does climate change refer to?'\n",
            "result : {'answer': 'What does climate change refer to?', 'context': 'Understanding Climate Change  \\nChapter 1: Introduction to Climate Change  \\nClimate change refers to significant, long -term changes in the global climate. The term \\n\"global climate\" encompasses the planet\\'s overall weather patterns, including temperature, \\nprecipitation, and wind patterns, over an extended period. Over the past cent ury, human \\nactivities, particularly the burning of fossil fuels and deforestation, have significantly \\ncontributed to climate change.  \\nHistorical Context  \\nThe Earth\\'s climate has changed throughout history. Over the past 650,000 years, there have \\nbeen seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \\n11,700 years ago marking the beginning of the modern climate era and  human civilization. \\nMost of these climate changes are attributed to very small variations in Earth\\'s orbit that \\nchange the amount of solar energy our planet receives. During the Holocene epoch, which Most of these climate changes are attributed to very small variations in Earth\\'s orbit that \\nchange the amount of solar energy our planet receives. During the Holocene epoch, which \\nbegan at the end of the last ice age, human societies f lourished, but the industrial era has seen \\nunprecedented changes.  \\nModern Observations  \\nModern scientific observations indicate a rapid increase in global temperatures, sea levels, \\nand extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \\ndocumented these changes extensively. Ice core samples, tree rings, and ocean sediments \\nprovide a historical record that scientists use to understand past climate conditions and \\npredict future trends. The evidence overwhelmingly shows that recent changes are primarily \\ndriven by human activities, particularly the emission of greenhou se gases.  \\nChapter 2: Causes of Climate Change  \\nGreenhouse Gases', 'question': 'What does climate change refer to?'}\n",
            "Answering the question from the retrieved context...\n",
            "output : None\n",
            "result : None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-7b565c741f9a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_rag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks_query_retriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-5052b2a4f15e>\u001b[0m in \u001b[0;36mevaluate_rag\u001b[0;34m(chunks_query_retriever, num_questions)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_question_from_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_answer_from_context_chain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"result : \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mgenerated_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Create test cases and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}
